{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import struct\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据集路径\n",
    "dataset_path = Path('./dataset')\n",
    "# 训练图片集路径\n",
    "train_img_path = './dataset/train-images-idx3-ubyte'\n",
    "train_lab_path = './dataset/train-labels-idx1-ubyte'\n",
    "test_img_path = './dataset/t10k-images-idx3-ubyte'\n",
    "test_lab_path = './dataset/t10k-labels-idx1-ubyte'\n",
    "\n",
    "dimensions = [28*28, 100, 10]\n",
    "\n",
    "distribution=[\n",
    "{},\n",
    "{'b':[0,0],'w':[-math.sqrt(6/(dimensions[0]+dimensions[1])),math.sqrt(6/(dimensions[0]+dimensions[1]))]},\n",
    "{'b':[0,0],'w':[-math.sqrt(6/(dimensions[1]+dimensions[2])),math.sqrt(6/(dimensions[1]+dimensions[2]))]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bypass(x):\n",
    "\treturn x\n",
    "\n",
    "def tanh(x):\n",
    "\treturn np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "\texp = np.exp(x-x.max())\n",
    "\treturn exp/exp.sum()\n",
    "\n",
    "# softmax导数函数\n",
    "def d_softmax(data):\n",
    "\tsm = softmax(data)\n",
    "\t# diag:对角矩阵  outer：第一个参数挨个乘以第二个参数得到矩阵\n",
    "\treturn np.diag(sm)-np.outer(sm,sm)\n",
    "\n",
    "# tanh导数函数优化：\n",
    "# import sympy as sy\n",
    "def d_tanh(data):\n",
    "\treturn 1/(np.cosh(data))**2\n",
    "\t# data = sy.symbols(\"data\", real=True)\n",
    "\t# return 1/(sy.cosh(data))**2\n",
    "\n",
    "def d_bypass(data):\n",
    "\treturn 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "activations = [bypass,tanh,softmax]\n",
    "differential = {softmax:d_softmax,tanh:d_tanh, bypass: d_bypass}\n",
    "\n",
    "def init_parameters_b(layer):\n",
    "    dist = distribution[layer]['b']\n",
    "    return np.random.rand(dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "\n",
    "#init_parameters_b(0)\n",
    "\n",
    "def init_parameters_w(layer):\n",
    "    dist = distribution[layer]['w']\n",
    "    return np.random.rand(dimensions[layer-1], dimensions[layer])*(dist[1]-dist[0])+dist[0]\n",
    "\n",
    "inits = {'b':init_parameters_b,'w':init_parameters_w}\n",
    "def init_parameters():\n",
    "    parameters = []\n",
    "    for i in range(len(distribution)):\n",
    "        layer_parameter = {}\n",
    "        for k in distribution[i].keys():\n",
    "            layer_parameter[k] = inits[k](i)\n",
    "            pass\n",
    "        parameters.append(layer_parameter)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(img, parameters):\n",
    "\tl_in = img\n",
    "\tl_out = activations[0](l_in)\n",
    "\tfor layer in range(1, len(dimensions)):\n",
    "\t\tl_in = np.dot(l_out, parameters[layer]['w']) + parameters[layer]['b']\n",
    "\t\tl_out = activations[layer](l_in)\n",
    "\treturn l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练50000个，验证10000个，测试10000个\n",
    "train_num = 50000\n",
    "valid_num = 10000\n",
    "test_num = 10000\n",
    "\n",
    "# 读入训练图片集和验证图片集\n",
    "with open(train_img_path,'rb') as f:\n",
    "\tstruct.unpack('>4i',f.read(16))\n",
    "\ttmp_img = np.fromfile(f,dtype = np.uint8).reshape(-1,28*28)\n",
    "\ttrain_img = tmp_img[:train_num]\n",
    "\tvalid_img = tmp_img[train_num:]\n",
    "\n",
    "# 读入测试图片集\n",
    "with open(test_img_path,'rb') as f:\n",
    "\tstruct.unpack('>4i',f.read(16))\n",
    "\ttest_img = np.fromfile(f,dtype = np.uint8).reshape(-1,28*28)\n",
    "\n",
    "# 读入训练标签和验证标签\n",
    "with open(train_lab_path,'rb') as f:\n",
    "\tstruct.unpack('>2i',f.read(8))\n",
    "\ttmp_lab = np.fromfile(f,dtype = np.uint8)\n",
    "\ttrain_lab = tmp_lab[:train_num]\n",
    "\tvalid_lab = tmp_lab[train_num:]\n",
    "\n",
    "# 读入测试标签\n",
    "with open(test_lab_path,'rb') as f:\n",
    "\tstruct.unpack('>2i',f.read(8))\n",
    "\ttest_lab = np.fromfile(f,dtype = np.uint8)\n",
    "\n",
    "# 展示训练图片\n",
    "def show_train(index):\n",
    "\tplt.imshow(train_img[index].reshape(28,28),cmap = 'gray')\n",
    "\tprint('label  = {}'.format(train_lab[index]))\n",
    "\tplt.show()\n",
    "\n",
    "# 展示验证图片\n",
    "def show_valid(index):\n",
    "\tplt.imshow(valid_img[index].reshape(28,28),cmap = 'gray')\n",
    "\tprint('label  = {}'.format(valid_lab[index]))\n",
    "\tplt.show()\n",
    "\n",
    "# 展示测试图片\n",
    "def show_test(index):\n",
    "\tplt.imshow(test_img[index].reshape(28,28),cmap = 'gray')\n",
    "\tprint('label  = {}'.format(test_lab[index]))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lab解析函数\n",
    "# 将数解析为某一位置为1的一维矩阵\n",
    "onehot = np.identity(dimensions[-1])\n",
    "# 递推求导\n",
    "d_type = {softmax:'dot', tanh:'times', bypass:'times'}\n",
    "\n",
    "# 求平方差函数\n",
    "def sqr_loss(img,lab,parameters):\n",
    "\ty_pred = predict(img,parameters)\n",
    "\ty = onehot[lab]\n",
    "\tdiff = y-y_pred\n",
    "\treturn np.dot(diff,diff)\n",
    "\n",
    "def grad_parameters(img, lab, parameters):\n",
    "\tl_in_list = [img]\n",
    "\tl_out_list = [activations[0](l_in_list[0])]\n",
    "\tfor layer in range(1, len(dimensions)):\n",
    "\t\tl_in = np.dot(l_out_list[layer-1], parameters[layer]['w']+parameters[layer]['b'])\n",
    "\t\tl_out = activations[layer](l_in)\n",
    "\t\tl_in_list.append(l_in)\n",
    "\t\tl_out_list.append(l_out)\n",
    "\n",
    "\td_layer = -2 * (onehot[lab] - l_out_list[-1])\n",
    "\n",
    "\tgrad_result = [None] * len(dimensions)\n",
    "\tfor layer in range(len(dimensions)-1, 0, -1):\n",
    "\t\tif d_type[activations[layer]] == 'times':\n",
    "\t\t\td_layer = differential[activations[layer]](l_in_list[layer]) * d_layer\n",
    "\t\telif d_type[activations[layer]] == 'dot':\n",
    "\t\t\td_layer = np.dot(differential[activations[layer]](l_in_list[layer]), d_layer)\n",
    "\t\tgrad_result[layer] = {}\n",
    "\t\tgrad_result[layer]['b'] = d_layer\n",
    "\t\tgrad_result[layer]['w'] = np.outer(l_out_list[layer-1], d_layer)\n",
    "\t\td_layer = np.dot(parameters[layer]['w'], d_layer)\n",
    "\n",
    "\treturn grad_result\n",
    "\n",
    "# 验证循环形式的 grad_parameters\n",
    "h = 0.0001\n",
    "layer = 2\n",
    "pname = 'b'\n",
    "parameters = init_parameters()\n",
    "for i in range(len(parameters[layer][pname])):\n",
    "\timg_i = np.random.randint(train_num)\n",
    "\ttest_parameters = init_parameters()\n",
    "\tderivative = grad_parameters(train_img[img_i], train_lab[img_i], test_parameters)[layer][pname]\n",
    "\tvalue1 = sqr_loss(train_img[img_i], train_lab[img_i], test_parameters)\n",
    "\ttest_parameters[layer][pname][i] += h\n",
    "\tvalue2 = sqr_loss(train_img[img_i], train_lab[img_i], test_parameters)\n",
    "\tprint(derivative[i] - (value2-value1)/h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer = 1\n",
    "pname = 'w'\n",
    "grad_list = []\n",
    "# for i in range(len(parameters[layer][pname])):\n",
    "# \tfor j in range(len(parameters[layer][pname][0])):\n",
    "# \t\timg_i = np.random.randint(train_num)\n",
    "# \t\ttest_parameters = init_parameters()\n",
    "# \t\tderivative = grad_parameters(train_img[img_i], train_lab[img_i], test_parameters)[layer][pname]\n",
    "# \t\tvalue1 = sqr_loss(train_img[img_i], train_lab[img_i], test_parameters)\n",
    "# \t\ttest_parameters[layer][pname][i][j] += h\n",
    "# \t\tvalue2 = sqr_loss(train_img[img_i], train_lab[img_i], test_parameters)\n",
    "# \t\tgrad_list.append(derivative[i][j] - (value2-value1)/h)\n",
    "# np.abs(grad_list).max()\n",
    "\n",
    "\n",
    "def valid_loss(parameters):\n",
    "    loss_accu = 0\n",
    "    for img_i in range(valid_num):\n",
    "        loss_accu += sqr_loss(valid_img[img_i], valid_lab[img_i], parameters)\n",
    "    return loss_accu/(valid_num/10000)\n",
    "\n",
    "def valid_accuracy(parameters):\n",
    "    correct = [predict(valid_img[img_i],parameters).argmax() == valid_lab[img_i] for img_i in range(valid_num)]\n",
    "    print('validation accuracy:%s' % (correct.count(True)/len(correct)))\n",
    "    return correct.count(True)/len(correct)\n",
    "\n",
    "def train_loss(parameters):\n",
    "    loss_accu = 0\n",
    "    for img_i in range(train_num):\n",
    "        loss_accu += sqr_loss(train_img[img_i], train_lab[img_i], parameters)\n",
    "    return loss_accu/(train_num/10000)\n",
    "\n",
    "def train_accuracy(parameters):\n",
    "    correct = [predict(train_img[img_i],parameters).argmax() == train_lab[img_i] for img_i in range(train_num)]\n",
    "    print('train accuracy:%s' % (correct.count(True)/len(correct)))\n",
    "    return correct.count(True)/len(correct)\n",
    "\n",
    "\n",
    "parameters = init_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "def train_batch(current_batch, parameters):\n",
    "\tb_0 = current_batch * batch_size\n",
    "\tgrad_accu = grad_parameters(train_img[b_0], train_lab[b_0], parameters)\n",
    "\tfor img_i in range(batch_size):\n",
    "\t\ti_b = b_0 + img_i\n",
    "\t\tgrad_b = grad_parameters(train_img[i_b], train_lab[i_b], parameters)\n",
    "\t\tgrad_add(grad_accu, grad_b)\n",
    "\tgrad_divide(grad_accu, batch_size)\n",
    "\treturn grad_accu\n",
    "\n",
    "def grad_add(grad1, grad2):\n",
    "\tfor layer in range(1, len(grad1)):# 第0层None\n",
    "\t\tfor pname in grad1[layer].keys():\n",
    "\t\t\tgrad1[layer][pname] += grad2[layer][pname]\n",
    "\treturn grad1\n",
    "\n",
    "def grad_divide(grad, denominator):\n",
    "\tfor layer in range(1, len(grad)):\n",
    "\t\tfor pname in grad[layer].keys():\n",
    "\t\t\tgrad[layer][pname] /= denominator\n",
    "\treturn grad\n",
    "\n",
    "def combine_parameters(parameters, grad, learn_rate):\n",
    "\tparameter_result = copy.deepcopy(parameters)\n",
    "\tfor layer in range(len(parameter_result)):\n",
    "\t\tfor pname in parameter_result[layer].keys():\n",
    "\t\t\tparameter_result[layer][pname] = np.subtract(parameter_result[layer][pname], learn_rate * grad[layer][pname])\n",
    "\treturn parameter_result\n",
    "\n",
    "\n",
    "def test_accuracy(parameters):\n",
    "\tcorrect = [predict(test_img[img_i],parameters).argmax() == test_lab[img_i] for img_i in range(test_num)]\n",
    "\tprint('test accuracy:%s' % (correct.count(True)/len(correct)))\n",
    "\treturn correct.count(True)/len(correct)\n",
    "\n",
    "train_loss_list = []\n",
    "train_accu_list = []\n",
    "valid_loss_list = []\n",
    "valid_accu_list = []\n",
    "\n",
    "valid_accuracy(parameters)\n",
    "# learn_rate = 2.1\n",
    "learn_rate = 0.05\n",
    "epoch_num = 5\n",
    "\n",
    "batch_count = train_num//batch_size\n",
    "print(batch_count)\n",
    "for epoch in range(epoch_num):\n",
    "\tprint(\"epoch:%s\" % epoch)\n",
    "\tfor i in range(batch_count):\n",
    "\t\tif i%100 == 99:\n",
    "\t\t\tprint('running batch %s/%s' % (i+1, batch_count))\n",
    "\t\tgrad_accu = train_batch(i, parameters)\n",
    "\t\tparameters = combine_parameters(parameters, grad_accu, learn_rate)\n",
    "\ttrain_loss_list.append(train_loss(parameters))\n",
    "\ttrain_accu_list.append(train_accuracy(parameters))\n",
    "\tvalid_loss_list.append(valid_loss(parameters))\n",
    "\tvalid_accu_list.append(valid_accuracy(parameters))\n",
    "\n",
    "valid_accuracy(parameters)\n",
    "lower = 0\n",
    "plt.plot(valid_loss_list[lower:], color='blue', label='validation loss')\n",
    "plt.plot(train_loss_list[lower:], color='red', label='train loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(valid_accu_list[lower:], color='blue', label='validation accuracy')\n",
    "plt.plot(train_accu_list[lower:], color='red', label='train accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_accuracy(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
